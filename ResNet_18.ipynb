{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9c174f-33c0-44fa-af53-14237d35b37d",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b35d923-b9e9-4ea4-914a-5bf05b93a2b5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.735267Z",
     "end_time": "2024-05-02T15:11:05.845291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 获取计算硬件\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9499c1-0594-48b8-80f0-e7fdbc30dbe3",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81f0ca03-de86-450d-a47e-6f0e7c19d97a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.743820Z",
     "end_time": "2024-05-02T15:11:05.992184Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d059c79-5b67-49fe-9baa-1bcd363208dc",
   "metadata": {},
   "source": [
    "## 载入图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcf6544a-6af5-4b07-93df-d863157b9290",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.753799Z",
     "end_time": "2024-05-02T15:11:06.063369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集路径 data\\train\n",
      "测试集路径 data\\val\n",
      "训练集图像数量 2360\n",
      "类别个数 24\n",
      "各类别名称 ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n",
      "测试集图像数量 590\n",
      "类别个数 24\n",
      "各类别名称 ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n"
     ]
    }
   ],
   "source": [
    "# 数据集文件夹路径\n",
    "dataset_dir = 'data'\n",
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('训练集路径', train_path)\n",
    "print('测试集路径', test_path)\n",
    "\n",
    "from torchvision import datasets\n",
    "# 载入训练集\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "# 载入测试集\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
    "\n",
    "print('训练集图像数量', len(train_dataset))\n",
    "print('类别个数', len(train_dataset.classes))\n",
    "print('各类别名称', train_dataset.classes)\n",
    "print('测试集图像数量', len(test_dataset))\n",
    "print('类别个数', len(test_dataset.classes))\n",
    "print('各类别名称', test_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e98be-4648-4d34-9e6c-273a55127b4d",
   "metadata": {},
   "source": [
    "## 类别和索引号 映射字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f737200-3afd-46f7-9c42-52c66829572e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.782361Z",
     "end_time": "2024-05-02T15:11:06.102634Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各类别名称\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)\n",
    "# 映射关系：类别 到 索引号\n",
    "train_dataset.class_to_idx\n",
    "# 映射关系：索引号 到 类别\n",
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0baa451-a3c8-456a-a1ad-ea814dc9958c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.786883Z",
     "end_time": "2024-05-02T15:11:06.105636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: '01',\n 1: '02',\n 2: '03',\n 3: '04',\n 4: '05',\n 5: '06',\n 6: '07',\n 7: '08',\n 8: '09',\n 9: '10',\n 10: '11',\n 11: '12',\n 12: '13',\n 13: '14',\n 14: '15',\n 15: '16',\n 16: '17',\n 17: '18',\n 18: '19',\n 19: '20',\n 20: '21',\n 21: '22',\n 22: '23',\n 23: '24'}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d3824-e6bb-4f50-9802-f073d9151311",
   "metadata": {},
   "source": [
    "## 定义数据加载器DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a787702d-61c6-41af-9cbd-19bc5d3baae7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.799421Z",
     "end_time": "2024-05-02T15:11:06.105636Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 训练集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# 测试集的数据加载器\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52d04-a791-4feb-8b57-af98b253ebba",
   "metadata": {},
   "source": [
    "## 导入训练需使用的工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "684da643-5a88-4ba2-b49c-5dc98b35100e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.804593Z",
     "end_time": "2024-05-02T15:11:06.106859Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b9c90-160f-451f-a46b-6e846424cc0a",
   "metadata": {},
   "source": [
    "## 选择迁移学习训练方式\n",
    "\n",
    "斯坦福CS231N【迁移学习】中文精讲：https://www.bilibili.com/video/BV1K7411W7So\n",
    "\n",
    "斯坦福CS231N【迁移学习】官方笔记：https://cs231n.github.io/transfer-learning\n",
    "\n",
    "如果你的数据集和MS COCO数据集的图像域**类似**（街景、动植物、生活用品），可以保留预训练模型权重，在自己的数据集上迁移学习微调分类输出层或所有层。站在巨人的肩膀上，复用预训练模型在MS COCO数据集上学习到的图像特征。（Transfer Learning, Fine Tuning）\n",
    "\n",
    "如果你的数据集和MS COCO数据集的图像域**不类似**（医疗影像、显微镜图像、工业检测、天文照片、动画、油画），可以随机初始化模型权重，在自己的数据集上重新训练所有层。（From Scratch）。或者冻结底层权重，只重新训练顶层，复用预训练模型在MS COCO数据集上学习到的底层图像特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf28f7-07f6-493a-b358-318b1a187a30",
   "metadata": {},
   "source": [
    "### 微调训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e00e1a34-19b7-47c7-ad7b-1a88d93ef709",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:05.815220Z",
     "end_time": "2024-05-02T15:11:06.183519Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65ef4401-6776-4dd7-aca5-a837cd24a6a9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:06.048015Z",
     "end_time": "2024-05-02T15:11:06.184030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=512, out_features=24, bias=True)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba0108df-0883-489d-bc73-5ff2bd071582",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:06.053600Z",
     "end_time": "2024-05-02T15:11:06.529134Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92213d-d6d9-435f-a4c0-4bcdbdf7c6b8",
   "metadata": {},
   "source": [
    "## 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5146eb0-f25e-400c-bbd6-e567f8aab8c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:06.531133Z",
     "end_time": "2024-05-02T15:11:06.942608Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# 训练轮次 Epoch\n",
    "EPOCHS = 30\n",
    "\n",
    "# 学习率降低策略\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36146f7-afb5-416e-a7d2-938c0fd6ab6a",
   "metadata": {},
   "source": [
    "## 函数：在训练集上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4fde230-042e-4e58-92eb-36d9febc8553",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:06.947179Z",
     "end_time": "2024-05-02T15:11:06.950186Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6511cc9-d9d8-4c67-9aed-e1c0ac14dbcb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:06.952702Z",
     "end_time": "2024-05-02T15:11:07.046503Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    "    '''\n",
    "    运行一个 batch 的训练，返回当前 batch 的训练日志\n",
    "    '''\n",
    "    \n",
    "    # 获得一个 batch 的数据和标注\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images) # 输入模型，执行前向预测\n",
    "    loss = criterion(outputs, labels) # 计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "    \n",
    "    # 优化更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 获取当前 batch 的标签类别和预测类别\n",
    "    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # 计算分类评估指标\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return log_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db850cdd-41eb-454a-957d-9af9dad9165b",
   "metadata": {},
   "source": [
    "## 函数：在整个测试集上评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "709a01fc-05c8-4c4e-abca-6fcded8c838a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:07.051259Z",
     "end_time": "2024-05-02T15:11:07.160992Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    '''\n",
    "    在整个测试集上评估，返回分类评估指标日志\n",
    "    '''\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader: # 生成一个 batch 的数据和标注\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) # 输入模型，执行前向预测\n",
    "\n",
    "            # 获取整个测试集的标签类别和预测类别\n",
    "            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    \n",
    "    # 计算分类评估指标\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练开始之前，记录日志"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T15:11:07.162998Z",
     "end_time": "2024-05-02T15:11:07.268326Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 运行训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000ce4e-7134-4c56-b95b-926cb5194b18",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T13:43:06.997182Z",
     "end_time": "2024-05-02T13:57:50.592362Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:39<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.195.pth\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:36<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.280.pth\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:53<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.336.pth\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:46<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:45<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.464.pth\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:46<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.586.pth\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:45<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:44<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.663.pth\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:39<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:47<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:41<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.697.pth\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:43<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.753.pth\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:43<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.788.pth\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:40<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:44<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:41<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.831.pth\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:40<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.846.pth\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:39<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:33<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:32<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:30<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.859.pth\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:30<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:29<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:28<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:30<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:39<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.878.pth\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:43<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存新的最佳模型 data/checkpoint/best-0.890.pth\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:42<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:42<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    \n",
    "    ## 训练阶段\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader): # 获得一个 batch 的数据和标注\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "    lr_scheduler.step()\n",
    "    ## 测试阶段\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    # 保存最新的最佳模型文件\n",
    "    if log_test['test_accuracy'] > best_test_accuracy: \n",
    "        # 删除旧的最佳模型文件(如有)\n",
    "        old_best_checkpoint_path = 'data/checkpoint/best-{:.3f}.pth'.format(best_test_accuracy)\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "        # 保存新的最佳模型文件\n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = 'data/checkpoint/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print('保存新的最佳模型', 'data/checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdafc8-fca1-48f1-8fea-e864c3293d74",
   "metadata": {},
   "source": [
    "## 在测试集上评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6512f03-53ff-428a-bff4-d151a2c57796",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:18:18.277366Z",
     "end_time": "2024-05-02T14:18:18.473176Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 载入最佳模型作为当前模型\n",
    "model = torch.load('data/checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238ad86-508f-4a86-affd-fa6f8016e9bb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:18:19.991376Z",
     "end_time": "2024-05-02T14:18:29.139149Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(evaluate_testset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0225f97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44e39fa3-29c0-489a-854e-b4df1c1bcf57",
   "metadata": {},
   "source": [
    "## 参考文档\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "https://www.bilibili.com/video/BV14J411X7Bb\n",
    "\n",
    "https://www.bilibili.com/video/BV1w4411u7ay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
